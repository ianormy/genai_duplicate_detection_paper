{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682d19cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import ast\n",
    "import tqdm\n",
    "import faiss\n",
    "from typing import Dict, List, Any, Tuple\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cdd4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'C:/Data/Musicbrainz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261b3291",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_folder, 'musicbrainz_200k_with_embeddings.csv'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d4d5a7",
   "metadata": {},
   "source": [
    "## Convert Embedding Vectors\n",
    "The embedding vectors have been stored as strings for CSV compatibility. This means that we need to convert them from string literals to a floating point array. Having done that we also want to convert those values to a numpy array of floating point values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac7ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['embedding'] = df['embedding_vector'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca56343",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.stack(df[\"embedding\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef5f16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ea5732",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_embeddings = embeddings.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba45f0b-1799-4b95-8965-47feeaa080cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_l2_index(db_vectors, db_ids, dims=768):\n",
    "    \"\"\"Create an L2 index using Faiss \n",
    "\n",
    "    :param db_vectors: vectors. Won't be changed\n",
    "    :param db_ids: list of IDs that correspond to the vectors\n",
    "    :param dims: dimensions of the vectors\n",
    "    \"\"\"\n",
    "    index = faiss.IndexFlatL2(dims)\n",
    "    index = faiss.IndexIDMap(index)\n",
    "    index.add_with_ids(db_vectors, db_ids)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28ff0c9-a7f0-4c15-8fad-77f8c5da3e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cosine_similarity_index(db_vectors, db_ids, dims=768):\n",
    "    \"\"\"Create a cosine similarity index using Faiss \n",
    "\n",
    "    :param db_vectors: vectors. Will get normalized\n",
    "    :param db_ids: list of IDs that correspond to the vectors\n",
    "    :param dims: dimensions of the vectors\n",
    "    \"\"\"\n",
    "    index = faiss.IndexFlatIP(dims)  # inner product\n",
    "    index = faiss.IndexIDMap(index)\n",
    "    faiss.normalize_L2(db_vectors)  # normalize the vectors before we add them\n",
    "    index.add_with_ids(db_vectors, db_ids)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799c6012",
   "metadata": {},
   "source": [
    "## Create Faiss Index\n",
    "To create our Faiss index we need our embedding vectors to be 32-bit floating point values and we also need a corresponding list of IDs as 64-bit integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73204d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_vectors = embeddings.copy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59c3b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_ids = df['TID'].values.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bf5484-fa49-4a5e-939e-7b43aa731e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = create_cosine_similarity_index(db_vectors, db_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a641fdf6",
   "metadata": {},
   "source": [
    "Double check that we have added all the records to the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61b406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total records in index: {index.ntotal:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd0d410",
   "metadata": {},
   "source": [
    "### Reverse Lookup Table\n",
    "Create a reverse lookup table so that we can go from an index to a **TID**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfd9311",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_lookup = {v: k for k, v in enumerate(db_ids)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c16b58",
   "metadata": {},
   "source": [
    "Check that the reverse lookup works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657d325d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_lookup[14722]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d5e69b",
   "metadata": {},
   "source": [
    "## Fetching Nearest Neighbours\n",
    "Let's perform a simple experiment to see if we can find the nearest neighbours to a given record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfafe4e-bf89-4bb8-80d7-0da0bf9390e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_neighbours(index_num: int, \n",
    "                     threshold: float = 0.1, \n",
    "                     max_cluster_size: int = 20) -> pd.DataFrame:\n",
    "    \"\"\"Fetch neigbours up to a maxiumn cluster size and limited to a threshold value\n",
    "    \n",
    "    :param index_num: the index to use to fetch the ID and embedding vector\n",
    "    :param threshold: threshold value to cut off nearest neighbours\n",
    "    :param maximum_cluster_size: maximum cluster size for nearest neighbours\n",
    "    :returns: a pandas DataFrame containing the nearest IDs and the distances\n",
    "    \"\"\"\n",
    "    match_ids = []\n",
    "    match_distances = []\n",
    "    query_id = db_ids[index_num]\n",
    "    query_vector = db_vectors[index_num,:].reshape([1, 768])\n",
    "    similarities, similarity_ids = index.search(query_vector, max_cluster_size)\n",
    "    for i in range(1, similarity_ids.shape[1]):\n",
    "        similarity_id = similarity_ids[0][i]\n",
    "        similarity = 1 - similarities[0][i]\n",
    "        if similarity <= threshold:\n",
    "            match_ids.append(similarity_id)\n",
    "            match_distances.append(similarity)\n",
    "        #print(f'{query_id}->{similarity_id} cosine sim: {similarity}', flush=True)\n",
    "    match_df = pd.DataFrame({'TID': match_ids, 'distance': match_distances})\n",
    "    return match_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85298103",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_num = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dea915",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Searching for nearest IDs to {db_ids[query_num]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018c362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_match = fetch_neighbours(index_num=query_num, threshold=0.25)\n",
    "df_match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39008893",
   "metadata": {},
   "source": [
    "Compare this with the actual cosine similarity between the 2 original vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f2fc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_vectors = np.zeros((2, 768), dtype='float')\n",
    "first_neighbour = df_match['TID'].iloc[0]\n",
    "distance_vectors[0, :] = orig_embeddings[query_num, :]\n",
    "distance_vectors[1, :] = orig_embeddings[reverse_lookup[first_neighbour], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7e40fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_dist = pdist(distance_vectors, metric='cosine')\n",
    "print(f'{db_ids[query_num]}->{first_neighbour} cosine distance: {cosine_dist[0]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6de33e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_match_group(matches_df: pd.DataFrame,\n",
    "                       visited: Dict[str, bool],\n",
    "                       match_group_id: str) -> List[Tuple[int, str, float]]:\n",
    "    \"\"\"Create the match group\n",
    "\n",
    "    :param matches_df: all the matches\n",
    "    :param visited: dictionary containing all the IDs that we have visited so far\n",
    "    :param match_group_id: match group ID to assign\n",
    "    \"\"\"\n",
    "    num_recs = 0\n",
    "    ret = []\n",
    "    for i in range(len(matches_df)):\n",
    "        match_id = matches_df['TID'].iloc[i]\n",
    "        distance = matches_df['distance'].iloc[i]\n",
    "        lookup_id = reverse_lookup[match_id]\n",
    "        if lookup_id not in visited.keys():\n",
    "            visited[lookup_id] = True\n",
    "            ret.append((match_id, match_group_id, distance))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16735793",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_match_group_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4d823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_next_match_group_id() -> str:\n",
    "    \"\"\"Uses the global current_match_group_id variable to calculate the next one\n",
    "\n",
    "    :returns: the next match group ID as a string\n",
    "    \"\"\"\n",
    "    global current_match_group_id\n",
    "    current_match_group_id += 1\n",
    "    return f'{current_match_group_id}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5560e1ca-31ff-44f4-b34a-843c83974972",
   "metadata": {},
   "outputs": [],
   "source": [
    "#epsilon = 0.2725\n",
    "#epsilon = 0.125\n",
    "#epsilon = 0.2\n",
    "#epsilon = 0.3\n",
    "#epsilon = 0.25\n",
    "epsilon = 0.245\n",
    "results_filename = 'match_groups_200k_epsilon_0_245.csv'\n",
    "metadata_filename = 'match_groups_200k_epsilon_0_245.json'\n",
    "results_folder = 'results'\n",
    "distance_metric = 'cosine_sim'\n",
    "experiment_params = {'epsilon': epsilon,\n",
    "                     'distance_metric': distance_metric,\n",
    "                    'total_recs': len(df)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9877a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_match_group_id = 1\n",
    "chunk_size = 5000 # 5K\n",
    "ids_visited = {}\n",
    "total_recs = len(df)\n",
    "progress_bar = tqdm(range(total_recs),\n",
    "                    file=open(os.devnull, 'w'),\n",
    "                    desc=\"match group update progress\")\n",
    "ids = range(len(df))\n",
    "ids_all = set(ids)\n",
    "ids_left = set(ids)\n",
    "max_chunk = 0\n",
    "last_progress = 0\n",
    "matches_found = []\n",
    "while len(ids_left) > 0:\n",
    "    i_random = random.choice(list(ids_left))\n",
    "    ids_visited[i_random] = True\n",
    "    matches_df = fetch_neighbours(index_num=i_random,\n",
    "                                  threshold=epsilon)\n",
    "    next_match_group_id = calc_next_match_group_id()\n",
    "    matches = create_match_group(matches_df=matches_df,\n",
    "                                 visited=ids_visited,\n",
    "                                 match_group_id=next_match_group_id)\n",
    "    if len(matches) > 0:\n",
    "        matches_found.append((db_ids[i_random], next_match_group_id, 0))\n",
    "        matches_found.extend(matches)\n",
    "    ids_left = ids_all.difference(set(ids_visited.keys()))\n",
    "    so_far = total_recs - len(ids_left)\n",
    "    this_update = so_far - last_progress\n",
    "    progress_bar.update(this_update)\n",
    "    if so_far // chunk_size > max_chunk:\n",
    "        print(str(progress_bar))\n",
    "        max_chunk = so_far // chunk_size\n",
    "    last_progress = so_far\n",
    "# print the final progress chunk\n",
    "this_update = total_recs - last_progress\n",
    "progress_bar.update(this_update)\n",
    "print(str(progress_bar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3350aaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_match_groups = pd.DataFrame(matches_found, columns=['TID', 'match_group_id', 'distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125e58d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_match_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4de5bcf-3cca-48ca-8f44-b75065c5426a",
   "metadata": {},
   "source": [
    "## Save the results\n",
    "Save the results so we can later visualise them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c71edbc-e38b-42d7-b3a8-4117ac03ffcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_match_groups.to_csv(os.path.join('results', results_filename), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
